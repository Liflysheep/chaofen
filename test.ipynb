{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "class SpectralDecoder(nn.Module):\n",
    "    def __init__(self, num_P, num_L,kernel_size=1, stride=1, padding=0, bias=False):\n",
    "        super(SpectralDecoder, self).__init__()\n",
    "        self.width = num_P\n",
    "        self.out_channels = num_L\n",
    "\n",
    "        # 定义一个 3D 卷积层\n",
    "        self.conv3d = nn.Conv3d(\n",
    "            in_channels=1,  # 输入通道数\n",
    "            out_channels=self.out_channels,  # 输出通道数\n",
    "            kernel_size=(self.width, 1, 1),  # 卷积核大小\n",
    "            stride=1,  # 步幅\n",
    "            padding=0  # 无填充\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_expanded = x.unsqueeze(1)  # 在维度 1 插入\n",
    "        output = self.conv3d(x.unsqueeze(1)).squeeze(2)\n",
    "\n",
    "\n",
    "        return output\n",
    "\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    # 定义输入和输出维度\n",
    "    b = 2    # 批次大小\n",
    "    p = 4    # 输入通道数\n",
    "    h = 3    # 输入高度\n",
    "    w = 3    # 输入宽度\n",
    "    l = 5   # 输出通道数\n",
    "\n",
    "    # 创建局部连接层实例\n",
    "    locally_connected = SpectralDecoder(\n",
    "        num_P=p,\n",
    "        num_L=l,\n",
    "        kernel_size=1,    # 根据需求，可以调整 kernel_size\n",
    "        stride=1,\n",
    "        padding=0,\n",
    "        bias=False        # 根据需求，决定是否使用偏置\n",
    "    )\n",
    "\n",
    "    # 输入张量 [b, p, h, w]\n",
    "    x = torch.randn(b, p, h, w)\n",
    "\n",
    "    # 前向传播\n",
    "    output = locally_connected(x)\n",
    "\n",
    "    # 输出形状应为 [b, l, h, w]\n",
    "    print(output.shape)  # 输出: torch.Size([2,5,3,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChannelWise1DEncoder(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels, kernel_size=3):\n",
    "        \"\"\"\n",
    "        1D 卷积编码器，用于通道间的上下文信息提取\n",
    "        :param input_channels: 输入通道数\n",
    "        :param output_channels: 输出通道数\n",
    "        :param kernel_size: 1D 卷积核大小 \n",
    "        \"\"\"\n",
    "        super(ChannelWise1DEncoder, self).__init__()\n",
    "        self.conv1d = nn.Conv1d(\n",
    "            in_channels=input_channels,\n",
    "            out_channels=output_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=1,\n",
    "            padding=(kernel_size - 1) // 2,  # 确保输入和输出的通道维度长度一致\n",
    "        )\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 将输入的通道维度切换为序列维度 (B, C, H, W) -> (B, H*W, C)\n",
    "        batch_size, channels, height, width = x.shape\n",
    "        x = x.permute(0, 2, 3, 1).reshape(batch_size, height * width, channels)  # (B, H*W, C)\n",
    "        # 应用 1D 卷积\n",
    "        x = self.conv1d(x)\n",
    "        x = self.relu(x)\n",
    "        # 恢复为原始维度 (B, H*W, C_out) -> (B, C_out, H, W)\n",
    "        x = x.reshape(batch_size, height, width, -1).permute(0, 3, 1, 2)  # (B, C_out, H, W)\n",
    "        return x\n",
    "\n",
    "# 测试代码\n",
    "if __name__ == \"__main__\":\n",
    "    input_tensor = torch.randn(4, 128, 25, 25)  # 假设输入为 Lr_HSI (B, C, H, W)\n",
    "    encoder = ChannelWise1DEncoder(input_channels=128, output_channels=64, kernel_size=3)\n",
    "    output_tensor = encoder(input_tensor)\n",
    "    print(f\"Output shape: {output_tensor.shape}\")  # 应输出: (4, 64, 25, 25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leida",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
